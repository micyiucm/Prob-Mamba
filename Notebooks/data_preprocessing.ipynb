{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d0065cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "repo_root = Path(\"/home/ubuntu/michael/MSc-Machine-Learning-Project\")\n",
    "src_path = repo_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "from preprocessing_pipeline import clean_and_select_features_equities, preprocess_data_equities, preprocess_data_crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d051be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redundant features\n",
    "redundant_nyse = [\n",
    "    'TE6', 'DTB6', 'DE4', 'TE5', 'DTB4WK', 'DAAA', \n",
    "    'DGS10', 'DE5', 'DTB3', 'DE6', 'EMA_20', 'CTB6M', \n",
    "    'CTB3M', 'EMA_50', 'CTB1Y', 'TE2', 'GSPC', 'DGS5', \n",
    "    'S&P-F', 'FCHI', 'EMA_200', 'GDAXI', 'oil', 'TE3', \n",
    "    'IXIC', 'HSI', 'FTSE', 'Dollar Index', 'DJI'\n",
    "    ]\n",
    "\n",
    "redundant_ixic = [\n",
    "    'DAAA', 'DTB6', 'DTB4WK', 'DGS10', 'TE3', 'DE4', \n",
    "    'TE2', 'DE5', 'DTB3', 'DE6', 'EMA_20', 'CTB6M', \n",
    "    'CTB3M', 'EMA_50', 'CTB1Y', 'EMA_200', 'DGS5', \n",
    "    'S&P-F', 'FCHI', 'GSPC', 'GDAXI', 'oil', 'NYSE', \n",
    "    'HSI', 'FTSE', 'Dollar Index', 'TE6', 'DJI'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7045e90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shifting 21 columns by +1 day\n",
      "Number of columns dropped: 34\n",
      "\n",
      "Shifting 21 columns by +1 day\n",
      "Number of columns dropped: 33\n"
     ]
    }
   ],
   "source": [
    "# Clean the data and save as feather\n",
    "df_nyse_raw = pd.read_feather(\"/home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/Raw/combined_dataframe_NYSE.feather\")\n",
    "df_nyse_cleaned = clean_and_select_features_equities(df_nyse_raw, redundant_nyse)\n",
    "df_nyse_cleaned.to_feather(\"/home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/Processed/cleaned_NYSE.feather\")\n",
    "\n",
    "df_ixic_raw = pd.read_feather(\"/home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/Raw/combined_dataframe_IXIC.feather\")\n",
    "df_ixic_cleaned = clean_and_select_features_equities(df_ixic_raw, redundant_ixic)\n",
    "df_ixic_cleaned.to_feather(\"/home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/Processed/cleaned_IXIC.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68cb9d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning pre-processing of /home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/Processed/cleaned_IXIC.feather:\n",
      "Loaded data from /home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/Processed/cleaned_IXIC.feather with 3470 rows and 51 columns.\n",
      "Dropping 1 leading rows with unresolved NaNs.\n",
      "Missing values handled.\n",
      "Split data chronologically:\n",
      "Training set: 2417 rows (<= 2019-08-12)\n",
      "Validation set: 484 rows (until 2021-07-14)\n",
      "Test set: 567 rows (after 2021-07-14)\n",
      "Scaler fitted on training data.\n",
      "Processed data saved for Processed/cleaned_IXIC.feather.\n",
      "\n",
      "Beginning pre-processing of /home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/Processed/cleaned_NYSE.feather:\n",
      "Loaded data from /home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/Processed/cleaned_NYSE.feather with 3470 rows and 50 columns.\n",
      "Dropping 1 leading rows with unresolved NaNs.\n",
      "Missing values handled.\n",
      "Split data chronologically:\n",
      "Training set: 2417 rows (<= 2019-08-12)\n",
      "Validation set: 484 rows (until 2021-07-14)\n",
      "Test set: 567 rows (after 2021-07-14)\n",
      "Scaler fitted on training data.\n",
      "Processed data saved for Processed/cleaned_NYSE.feather.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data pre-processing\n",
    "if __name__ == \"__main__\":\n",
    "    # Data directory\n",
    "    data_dir = \"/home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/\"\n",
    "\n",
    "    # Per-file cut-off dates\n",
    "    split_params = {\n",
    "        \"Processed/cleaned_IXIC.feather\":   dict(train_end=\"2019-08-12\", val_end=\"2021-07-14\"),\n",
    "        \"Processed/cleaned_NYSE.feather\":   dict(train_end=\"2019-08-12\", val_end=\"2021-07-14\")\n",
    "    }\n",
    "    # Process each file\n",
    "    for feather_file in [\"Processed/cleaned_IXIC.feather\",\n",
    "                         \"Processed/cleaned_NYSE.feather\"]:\n",
    "        feather_path = os.path.join(data_dir, feather_file)\n",
    "        try:\n",
    "            # Look up per-file dates (fallback to {} ‚Üí defaults)\n",
    "            params = split_params.get(feather_file, {})\n",
    "            train_df, val_df, test_df, scaler = preprocess_data_equities(\n",
    "                feather_path,\n",
    "                **params  # expands to train_end=..., val_end=...\n",
    "            )\n",
    "\n",
    "            # Save processed splits\n",
    "            stem = feather_file.replace(\".feather\", \"\")\n",
    "            train_df.to_feather(os.path.join(data_dir, f\"{stem}_train.feather\"))\n",
    "            val_df.to_feather(os.path.join(data_dir, f\"{stem}_val.feather\"))\n",
    "            test_df.to_feather(os.path.join(data_dir, f\"{stem}_test.feather\"))\n",
    "            print(f\"Processed data saved for {feather_file}.\\n\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"File not found: {e}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {feather_file}: {e}\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27d1a8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning pre-processing of /home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/Raw/BTC_USDT-5m.feather:\n",
      "Converting timezone-aware datetime (UTC) to UTC timezone-naive\n",
      "Loaded data from /home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/Raw/BTC_USDT-5m.feather with 104923 rows and 6 columns.\n",
      "Dropping 1 leading rows with unresolved NaNs.\n",
      "Missing values handled.\n",
      "Split data chronologically:\n",
      "Training set: 64626 rows (<= 2021-08-13)\n",
      "Validation set: 24744 rows (until 2021-11-07)\n",
      "Test set: 15551 rows (after 2021-11-07)\n",
      "Scaler fitted on training data.\n",
      "Processed data saved for BTC_USDT-5m.feather.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data pre-processing for crypto\n",
    "if __name__ == \"__main__\":\n",
    "    # Data directory\n",
    "    data_dir = \"/home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/Raw/\"\n",
    "\n",
    "    # Per-file cut-off dates\n",
    "    split_params = {\n",
    "        \"BTC_USDT-5m.feather\":   dict(train_end=\"2021-08-13 23:59:59\", val_end=\"2021-11-07 23:59:59\")\n",
    "    }\n",
    "    for feather_file in [\"BTC_USDT-5m.feather\"]:\n",
    "        feather_path = os.path.join(data_dir, feather_file)\n",
    "        try:\n",
    "            # Look up per-file dates (fallback to {} ‚Üí defaults)\n",
    "            params = split_params.get(feather_file, {})\n",
    "            \n",
    "            # Use crypto-specific preprocessing function\n",
    "            train_df, val_df, test_df, scaler = preprocess_data_crypto(\n",
    "                feather_path,\n",
    "                **params  # expands to train_end=..., val_end=...\n",
    "            )\n",
    "\n",
    "            # Save processed splits\n",
    "            save_dir = \"/home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/Processed\"\n",
    "            Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "            stem = feather_file.replace(\".feather\", \"\")\n",
    "            train_df.to_feather(os.path.join(save_dir, f\"{stem}_train.feather\"))\n",
    "            val_df.to_feather(os.path.join(save_dir, f\"{stem}_val.feather\"))\n",
    "            test_df.to_feather(os.path.join(save_dir, f\"{stem}_test.feather\"))\n",
    "            print(f\"Processed data saved for {feather_file}.\\n\")\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"File not found: {e}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {feather_file}: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe1b28ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä BTC Dataset Time Range Analysis:\n",
      "Shape: (524607, 6)\n",
      "\n",
      "üìÖ Date Range (date):\n",
      "Start: 2021-01-01 00:00:00+00:00\n",
      "End:   2021-12-31 23:59:00+00:00\n",
      "Duration: 364 days 23:59:00\n",
      "\n",
      "üïê Sample timestamps:\n",
      "  [0] 2021-01-01 00:00:00+00:00\n",
      "  [131151] 2021-04-02 04:40:00+00:00\n",
      "  [262303] 2021-07-02 13:46:00+00:00\n",
      "  [393455] 2021-10-01 22:08:00+00:00\n",
      "  [524606] 2021-12-31 23:59:00+00:00\n",
      "\n",
      "‚è±Ô∏è  Most common frequency: 0 days 00:01:00\n"
     ]
    }
   ],
   "source": [
    "# Check BTC data range to understand the timestamps\n",
    "import pandas as pd\n",
    "\n",
    "btc_path = \"/home/ubuntu/michael/MSc-Machine-Learning-Project/Datasets/Raw/BTC_USDT-1m.feather\"\n",
    "df_check = pd.read_feather(btc_path)\n",
    "\n",
    "print(\"üìä BTC Dataset Time Range Analysis:\")\n",
    "print(f\"Shape: {df_check.shape}\")\n",
    "\n",
    "# Find date column\n",
    "date_col = \"date\" if \"date\" in df_check.columns else \"Date\"\n",
    "df_check[date_col] = pd.to_datetime(df_check[date_col])\n",
    "\n",
    "print(f\"\\nüìÖ Date Range ({date_col}):\")\n",
    "print(f\"Start: {df_check[date_col].min()}\")\n",
    "print(f\"End:   {df_check[date_col].max()}\")\n",
    "print(f\"Duration: {df_check[date_col].max() - df_check[date_col].min()}\")\n",
    "\n",
    "# Check some sample timestamps\n",
    "print(f\"\\nüïê Sample timestamps:\")\n",
    "for i in [0, len(df_check)//4, len(df_check)//2, 3*len(df_check)//4, -1]:\n",
    "    if i >= 0:\n",
    "        idx = i\n",
    "    else:\n",
    "        idx = len(df_check) + i\n",
    "    print(f\"  [{idx}] {df_check[date_col].iloc[idx]}\")\n",
    "\n",
    "# Check frequency\n",
    "time_diff = df_check[date_col].diff().dropna()\n",
    "most_common_freq = time_diff.mode()\n",
    "if len(most_common_freq) > 0:\n",
    "    print(f\"\\n‚è±Ô∏è  Most common frequency: {most_common_freq.iloc[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prob_mamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
